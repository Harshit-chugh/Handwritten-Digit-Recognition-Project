{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b131fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "from scipy.ndimage import center_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753ffcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72378714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_image(img_arr):\n",
    "    mask = img_arr < 128\n",
    "    if not np.any(mask):  \n",
    "        return img_arr\n",
    "    cy, cx = center_of_mass(mask)\n",
    "    if np.isnan(cx) or np.isnan(cy):\n",
    "        return img_arr\n",
    "    shiftx = np.round(img_arr.shape[1] / 2.0 - cx).astype(int)\n",
    "    shifty = np.round(img_arr.shape[0] / 2.0 - cy).astype(int)\n",
    "    return np.roll(np.roll(img_arr, shifty, axis=0), shiftx, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462ace61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thicken(arr, k=2):\n",
    "    kernel = np.ones((k, k), np.uint8)\n",
    "    return cv2.dilate(arr, kernel, iterations=1)\n",
    "\n",
    "def preprocess(img):\n",
    "    im = Image.fromarray(img)\n",
    "\n",
    "    if im.mode == \"RGBA\":  \n",
    "        _, _, _, a = im.split()\n",
    "        im = a\n",
    "\n",
    "    im = im.convert(\"L\")               \n",
    "    im = ImageOps.invert(im)           \n",
    "    bbox = im.getbbox()\n",
    "    if bbox:\n",
    "        im = im.crop(bbox)             \n",
    "    im = im.resize((20, 20), Image.LANCZOS)\n",
    "    im = ImageOps.pad(im, (28, 28), color=255, centering=(0.5, 0.5))\n",
    "\n",
    "    arr = np.array(im)\n",
    "    arr = (arr < 128).astype(np.uint8) * 255  \n",
    "    arr = center_image(arr)                   \n",
    "    arr = thicken(arr, k=2)                   \n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c60e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch_recognition(img):\n",
    "    if img is None:\n",
    "        return {}, None\n",
    "\n",
    "    composite = img[\"composite\"]\n",
    "    arr = preprocess(composite)\n",
    "\n",
    "    x = arr.astype(\"float32\") / 255.0\n",
    "    x = x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    preds = model.predict(x).tolist()[0]\n",
    "\n",
    "    return {str(i): preds[i] for i in range(10)}, arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b19914ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=sketch_recognition,\n",
    "    inputs=gr.Sketchpad(type=\"numpy\"),  \n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=3),              \n",
    "        gr.Image(type=\"numpy\", image_mode=\"L\")    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683c795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
     ]
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a82e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
